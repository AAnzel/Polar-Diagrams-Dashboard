{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91c064a-3452-4bf5-9b67-94fba6b704bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polar_diagrams\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, callback, State, ctx, Patch\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "_INT_CHART_WIDTH = 1400\n",
    "_INT_CHART_HEIGHT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e89a60c-01fd-410a-b6cd-60435c923910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od_diluted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od_diluted  \n",
       "0          3.92  \n",
       "1          3.40  \n",
       "2          3.17  \n",
       "3          3.45  \n",
       "4          2.93  \n",
       "..          ...  \n",
       "173        1.74  \n",
       "174        1.56  \n",
       "175        1.56  \n",
       "176        1.62  \n",
       "177        1.60  \n",
       "\n",
       "[178 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine_data = load_wine(return_X_y=False, as_frame=True)['data']\n",
    "df_wine_data['od_diluted'] = df_wine_data['od280/od315_of_diluted_wines']\n",
    "df_wine_data.drop(['od280/od315_of_diluted_wines', 'proline'], axis=1,\n",
    "                  inplace=True)\n",
    "df_wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d851874-0d96-4852-9090-918d61a3777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alcohol': 'alcohol', 'malic_acid': 'Cluster 2', 'flavanoids': 'Cluster 2', 'color_intensity': 'Cluster 2', 'od_diluted': 'Cluster 2', 'ash': 'Cluster 3', 'hue': 'Cluster 3', 'alcalinity_of_ash': 'Cluster 4', 'magnesium': 'Cluster 4', 'total_phenols': 'Cluster 5', 'proanthocyanins': 'Cluster 5', 'nonflavanoid_phenols': 'Cluster 6'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 462\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PreventUpdate\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chart_left_updated, chart_right_updated\n\u001b[0;32m--> 462\u001b[0m \u001b[43mapp_create_dashboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_wine_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malcohol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscaled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 275\u001b[0m, in \u001b[0;36mapp_create_dashboard\u001b[0;34m(df_input, string_reference_model, string_diagram_type, string_mid_type)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m string_diagram_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    271\u001b[0m         string_mid_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m list_valid_mid_types):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_mid_type not in \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    273\u001b[0m                      \u001b[38;5;28mstr\u001b[39m(list_valid_mid_types))\n\u001b[0;32m--> 275\u001b[0m chart_left, dict_model_cluster \u001b[38;5;241m=\u001b[39m _chart_create_initial_left_diagram(\n\u001b[1;32m    276\u001b[0m     df_input, string_reference_model, string_diagram_type, string_mid_type)\n\u001b[1;32m    278\u001b[0m chart_right, string_warnings \u001b[38;5;241m=\u001b[39m _tuple_create_initial_right_diagram(\n\u001b[1;32m    279\u001b[0m     df_input, string_reference_model, string_diagram_type, string_mid_type)\n\u001b[1;32m    281\u001b[0m chart_left, chart_right \u001b[38;5;241m=\u001b[39m _tuple_style_both_diagrams(\n\u001b[1;32m    282\u001b[0m     chart_left, chart_right)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def _grid_search(df_left_input, string_reference_model, list_measures):\n",
    "\n",
    "    # We save the row with the reference model\n",
    "    # TODO: Implement check for duplicate reference models in the library\n",
    "    df_reference_row = df_left_input.loc[\n",
    "        df_left_input['Model'] == string_reference_model]\n",
    "    # We remove the reference row from the dataframe\n",
    "    df_input_no_reference = df_left_input.drop(\n",
    "        df_reference_row.index)[list_measures]\n",
    "\n",
    "    list_min_samples = np.arange(2, 15, step=2)\n",
    "    list_epsilons = np.linspace(0.01, 5, num=50)\n",
    "    list_hyperparam = list(itertools.product(list_epsilons, list_min_samples))\n",
    "\n",
    "    list_scores = []\n",
    "    list_labels_over_runs = []\n",
    "\n",
    "    for i, (float_eps, int_min_samples) in enumerate(list_hyperparam):\n",
    "        constructor_DBSCAN = DBSCAN(\n",
    "            eps=float_eps, min_samples=int_min_samples, n_jobs=-1)\n",
    "        constructor_DBSCAN.fit_predict(df_input_no_reference)\n",
    "        list_labels = constructor_DBSCAN.labels_\n",
    "\n",
    "        # We check if we have all outliers or all elements in seperate clusters\n",
    "        # These are the edge cases which we do not want\n",
    "        if len(set(list_labels)) == 1 or (\n",
    "                len(set(list_labels)) == len(list_labels)):\n",
    "            continue\n",
    "\n",
    "        list_scores.append(\n",
    "            silhouette_score(df_input_no_reference, list_labels))\n",
    "        list_labels_over_runs.append(list_labels)\n",
    "\n",
    "    int_best_score_index = np.argmax(list_scores)\n",
    "    np_array_best_labels = list(list_labels_over_runs[int_best_score_index])\n",
    "    # We add the label for the reference model at the same place that model\n",
    "    # was before we removed the entire row it was contained in\n",
    "    # We add a value of df_input.shape[0] because the model must not be a part\n",
    "    # of any cluster\n",
    "    np_array_best_labels.insert(\n",
    "        df_reference_row.index.values[0], df_left_input.shape[0])\n",
    "\n",
    "    tuple_best_hyperparam = list_hyperparam[int_best_score_index]\n",
    "\n",
    "    return tuple_best_hyperparam, np_array_best_labels\n",
    "\n",
    "\n",
    "def _tuple_group_left_dataframe(df_left_input, string_reference_model):\n",
    "    dict_aggregate_rules = {'Model': '; '.join}\n",
    "    for i in df_left_input.columns.to_list():\n",
    "        if i not in ['Model', 'Label']:\n",
    "            dict_aggregate_rules[i] = 'mean'\n",
    "\n",
    "    df_grouped_rows = df_left_input.groupby(\n",
    "        'Label', as_index=False, sort=False).agg(\n",
    "        dict_aggregate_rules).reset_index(drop=True)\n",
    "    df_grouped_rows['Cluster Count'] = [\n",
    "        int_i.count('; ') + 1 for int_i in list(df_grouped_rows['Model'])]\n",
    "\n",
    "    dict_model_cluster_correspondence = {}\n",
    "    list_new_model_names = []\n",
    "    for int_i, str_model in enumerate(df_grouped_rows['Model'].to_list()):\n",
    "\n",
    "        # The code below names only Clusters those traces that have multiple\n",
    "        # model names. If there is only one model name, then it is left as is\n",
    "        # and not named 'Cluster number'\n",
    "        #if '; ' in str_model:\n",
    "        #    list_new_model_names.append('Cluster ' + str(int_i + 1))\n",
    "        #else:\n",
    "        #    list_new_model_names.append(str_model)\n",
    "\n",
    "        # The code below names only Clusters those traces that are different\n",
    "        # than the reference model\n",
    "        if string_reference_model == str_model:\n",
    "            list_new_model_names.append(str_model)\n",
    "        else:\n",
    "            list_new_model_names.append('Cluster ' + str(int_i + 1))\n",
    "\n",
    "        for str_one_model in str_model.split('; '):\n",
    "            if str_one_model == string_reference_model:\n",
    "                dict_model_cluster_correspondence[\n",
    "                    str_one_model] = string_reference_model\n",
    "            else:\n",
    "                dict_model_cluster_correspondence[\n",
    "                    str_one_model] = 'Cluster ' + str(int_i + 1)\n",
    "\n",
    "    df_grouped_rows['Model'] = list_new_model_names\n",
    "\n",
    "    return df_grouped_rows, dict_model_cluster_correspondence\n",
    "\n",
    "\n",
    "def _chart_create_left_chart(df_grouped_data, string_reference_model,\n",
    "                            string_diagram_type, string_mid_type):\n",
    "    chart_left = polar_diagrams.polar_diagrams._chart_create_diagram(\n",
    "        [df_grouped_data],\n",
    "        string_reference_model=string_reference_model,\n",
    "        string_diagram_type=string_diagram_type,\n",
    "        string_mid_type=string_mid_type,\n",
    "        bool_normalized_measures=False)\n",
    "\n",
    "    dict_left = chart_left.to_dict()\n",
    "    for int_i in range(len(dict_left['data'])):\n",
    "        #dict_left['data'][int_i]['showlegend'] = False\n",
    "\n",
    "        if dict_left['data'][int_i]['name'].split(\n",
    "                '. ')[1] == string_reference_model:\n",
    "            continue\n",
    "\n",
    "        dict_left['data'][int_i]['mode'] = 'markers+text'\n",
    "        dict_left['data'][int_i]['text'] = '<b>' + str(\n",
    "            df_grouped_data['Cluster Count'][int_i]) + '</b>'\n",
    "        dict_left['data'][int_i]['marker']['color'] = 'rgba(100,100,100,0)'\n",
    "        dict_left['data'][int_i]['marker']['size'] = 20 + int(\n",
    "            10 * int(df_grouped_data['Cluster Count'][int_i])/10)\n",
    "        dict_left['data'][int_i]['marker']['line']['color'] = 'rgba(0,0,0,0.5)'\n",
    "\n",
    "    return go.Figure(dict_left)\n",
    "\n",
    "\n",
    "def _tuple_create_initial_left_diagram(df_input, string_reference_model,\n",
    "                                       string_diagram_type, string_mid_type):\n",
    "    # Here we create a DataFrame for the left chart with the clustered models\n",
    "    if string_diagram_type == 'taylor':\n",
    "        df_left_input = polar_diagrams.df_calculate_td_properties(\n",
    "            df_input, string_reference_model)\n",
    "        list_relevant_measures = ['Standard Deviation', 'Correlation', 'CRMSE']\n",
    "    else:\n",
    "        df_left_input = polar_diagrams.df_calculate_mid_properties(\n",
    "            df_input, string_reference_model)\n",
    "        if string_mid_type == 'scaled':\n",
    "            list_relevant_measures = ['Entropy', 'Scaled MI', 'VI']\n",
    "        else:\n",
    "            list_relevant_measures = ['Root Entropy', 'Normalized MI', 'RVI']\n",
    "\n",
    "    tuple_hyperparam, np_array_labels = _grid_search(\n",
    "        df_left_input,\n",
    "        string_reference_model=string_reference_model,\n",
    "        list_measures=list_relevant_measures)\n",
    "    df_left_input['Label'] = np_array_labels\n",
    "\n",
    "    df_left_grouped, dict_model_cluster = _tuple_group_left_dataframe(\n",
    "        df_left_input, string_reference_model)\n",
    "\n",
    "    chart_left = _chart_create_left_chart(\n",
    "        df_left_grouped, string_reference_model, string_diagram_type,\n",
    "        string_mid_type).update_layout(\n",
    "        dragmode='zoom', clickmode='event+select', hovermode=False,\n",
    "        width=round(_INT_CHART_WIDTH/3),\n",
    "        height=_INT_CHART_HEIGHT-100,\n",
    "        margin={'l':40, 'r':40})\n",
    "\n",
    "    return chart_left, dict_model_cluster\n",
    "\n",
    "\n",
    "def _tuple_create_initial_right_diagram(df_input, string_reference_model,\n",
    "                                        string_diagram_type, string_mid_type):\n",
    "\n",
    "    list_warning_caught = None\n",
    "    # We monkey patch the function that prints the warnings so that it doesn't\n",
    "    # require some inputs and only returns the warning message that we need\n",
    "    warnings.formatwarning = lambda msg, *args, **kwargs: str(msg)\n",
    "\n",
    "    if string_diagram_type == 'mid':\n",
    "        with warnings.catch_warnings(record=True) as warning_tmp:\n",
    "            # Cause all warnings to always be triggered.\n",
    "            warnings.simplefilter(\"default\")\n",
    "            chart_right = polar_diagrams.chart_create_mi_diagram(\n",
    "                df_input, string_reference_model=string_reference_model,\n",
    "                string_mid_type=string_mid_type).update_layout(\n",
    "                dragmode='select', clickmode='event+select',\n",
    "                width=int(_INT_CHART_WIDTH),\n",
    "                height=_INT_CHART_HEIGHT*1.4,\n",
    "                margin={'l':150, 'r':40})\n",
    "\n",
    "            list_warning_caught = warning_tmp\n",
    "    else:\n",
    "        with warnings.catch_warnings(record=True) as warning_tmp:\n",
    "            # Cause all warnings to always be triggered.\n",
    "            warnings.simplefilter(\"default\")\n",
    "            chart_right = polar_diagrams.chart_create_taylor_diagram(\n",
    "                df_input,\n",
    "                string_reference_model=string_reference_model).update_layout(\n",
    "                dragmode='select', clickmode='event+select',\n",
    "                width=int(_INT_CHART_WIDTH),\n",
    "                height=_INT_CHART_HEIGHT*1.4,\n",
    "                margin={'l':150, 'r':40})\n",
    "\n",
    "            list_warning_caught = warning_tmp\n",
    "\n",
    "    string_warnings = ''\n",
    "    int_i = 1\n",
    "    for warning_tmp in list_warning_caught:\n",
    "        if 'RuntimeWarning' in warnings.formatwarning(warning_tmp):\n",
    "            string_one_warning = warnings.formatwarning(\n",
    "                warning_tmp)[11:208].replace('\\\\n', ' ')\n",
    "            if string_one_warning in string_warnings:\n",
    "                continue\n",
    "            else:\n",
    "                string_warnings += str(int_i) + '. ' + string_one_warning\n",
    "                int_i += 1\n",
    "\n",
    "    return chart_right, string_warnings\n",
    "\n",
    "\n",
    "def _tuple_style_both_diagrams(chart_left, chart_right):\n",
    "\n",
    "    # We use the same radial and angular axis range for both diagrams. This\n",
    "    # fixes the edge cases where we have different axis ranges because of the\n",
    "    # left overview diagram. This diagram can have for example the angular axis\n",
    "    # 0-90 and not 0-180 as the right diagram because of the aggregation of\n",
    "    # some models during clustering (thus aggregating their coordinates)\n",
    "    chart_left.update_layout(\n",
    "        title=None,\n",
    "        polar_radialaxis_range=chart_right[\n",
    "            'layout']['polar'][\"radialaxis\"][\"range\"],\n",
    "        polar_radialaxis_ticklen=0,\n",
    "        polar_radialaxis_showticklabels=False,\n",
    "        polar_radialaxis_linewidth=0.5,\n",
    "        polar_radialaxis_layer='below traces',\n",
    "        polar_radialaxis_autorange=False,\n",
    "        polar_radialaxis_rangemode='normal',\n",
    "        polar_radialaxis_title=None,\n",
    "        polar_angularaxis=chart_right['layout']['polar'][\"angularaxis\"],\n",
    "        polar_angularaxis_layer='below traces',\n",
    "        polar_angularaxis_ticklen=0,\n",
    "        polar_angularaxis_showticklabels=False,\n",
    "        polar_angularaxis_linewidth=0.5,\n",
    "        polar_sector=[\n",
    "            0, chart_right['layout']['polar'][\"angularaxis\"]['tickvals'][0]],\n",
    "    )\n",
    "\n",
    "    # We vertically orient the legend of the right diagram\n",
    "    chart_right.update_layout(\n",
    "        legend_orientation='v',\n",
    "        legend_x=-0.3,\n",
    "        legend_y=1)\n",
    "\n",
    "    # We disable a legend for the second diagram by traversing traces\n",
    "    #dict_right = chart_right.to_dict()\n",
    "    #for int_i in range(len(dict_right['data'])):\n",
    "    #    dict_right['data'][int_i]['showlegend'] = False\n",
    "    #chart_right = go.Figure(dict_right)\n",
    "\n",
    "    return chart_left, chart_right\n",
    "\n",
    "\n",
    "def app_create_dashboard(df_input, string_reference_model,\n",
    "                         string_diagram_type='taylor',\n",
    "                         string_mid_type='normalized'):\n",
    "    dash_app = Dash(\"Polar Diagrams Dashboard\",\n",
    "                    external_stylesheets=[dbc.themes.BOOTSTRAP],\n",
    "                    meta_tags=[{\"name\": \"viewport\",\n",
    "                                \"content\": \"width=device-width\"}],)\n",
    "    dash_app.title = \"Polar Diagrams Dashboard\"\n",
    "    dash_app.css.config.serve_locally = True\n",
    "    dash_app.scripts.config.serve_locally = True\n",
    "\n",
    "    # ====================================================\n",
    "    # TODO: Raise an exception if a list of dataframes is provided where the\n",
    "    # TODO: second data set is not with scalar values\n",
    "    # TODO: We don't want to support two-version model functionality\n",
    "    # ====================================================\n",
    "    list_valid_diagram_types = ['taylor', 'mid']\n",
    "    list_valid_mid_types = ['scaled', 'normalized']\n",
    "\n",
    "    if string_diagram_type not in list_valid_diagram_types:\n",
    "        raise ValueError('string_diagram_type not in ' +\n",
    "                         str(list_valid_diagram_types))\n",
    "\n",
    "    if string_diagram_type == 'mid' and (\n",
    "            string_mid_type not in list_valid_mid_types):\n",
    "        raise ValueError('string_mid_type not in ' +\n",
    "                         str(list_valid_mid_types))\n",
    "\n",
    "    chart_left, dict_model_cluster = _tuple_create_initial_left_diagram(\n",
    "        df_input, string_reference_model, string_diagram_type, string_mid_type)\n",
    "\n",
    "    chart_right, string_warnings = _tuple_create_initial_right_diagram(\n",
    "        df_input, string_reference_model, string_diagram_type, string_mid_type)\n",
    "\n",
    "    chart_left, chart_right = _tuple_style_both_diagrams(\n",
    "        chart_left, chart_right)\n",
    "\n",
    "    global _FLOAT_MAX_R\n",
    "    _FLOAT_MAX_R = chart_left['layout']['polar']['radialaxis']['range'][1]\n",
    "    global _INT_MAX_THETA\n",
    "    _INT_MAX_THETA = chart_left['layout']['polar']['angularaxis'][\n",
    "        'tickvals'][0]\n",
    "\n",
    "    dash_app.layout = dbc.Container(\n",
    "        [\n",
    "            dbc.Row(\n",
    "                    html.Div(\n",
    "                        html.H1(\"Polar Diagrams Dashboard\"),\n",
    "                        style={\"font-family\": 'open sans',\n",
    "                               'margin-top': 50,\n",
    "                               'margin-bottom': 50})),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col([\n",
    "                        dcc.Graph(\n",
    "                            id=\"chart-left\",\n",
    "                            figure=chart_left,\n",
    "                            config={\n",
    "                                'modeBarButtonsToRemove': [\n",
    "                                    'zoom', 'select', 'pan', 'lasso', 'zoomIn',\n",
    "                                    'zoomOut', 'autoScale', 'resetScale'],\n",
    "                                'staticPlot': False,\n",
    "                                'displaylogo': False,\n",
    "                                'showAxisDragHandles': False}),\n",
    "                        html.Div(\n",
    "                            dbc.Alert(\n",
    "                                string_warnings,\n",
    "                                color=\"warning\",\n",
    "                                is_open=True if string_warnings != '' else False))],\n",
    "                        width=3,\n",
    "                        align='start',\n",
    "                        style={'border': '1px solid', 'margin-left': 0, 'margin-right':0}),\n",
    "                    dbc.Col(\n",
    "                        dcc.Graph(\n",
    "                            id=\"chart-right\",\n",
    "                            figure=chart_right,\n",
    "                            config={\n",
    "                                'modeBarButtonsToRemove': [\n",
    "                                    'zoom', 'pan', 'lasso', 'zoomIn',\n",
    "                                    'zoomOut', 'select', 'autoScale',\n",
    "                                    'resetScale'],\n",
    "                                'displaylogo': False,\n",
    "                                'showAxisDragHandles': False}),\n",
    "                        width=True,\n",
    "                        align='start',\n",
    "                        style={'border': '1px solid'})\n",
    "                ],\n",
    "                className=\"g-0\",\n",
    "                justify=\"center\",\n",
    "            ),\n",
    "        ],\n",
    "        fluid=True)\n",
    "\n",
    "    dash_app.run(debug=True, jupyter_mode='external')\n",
    "\n",
    "    return None\n",
    "\n",
    "'''\n",
    "@callback(\n",
    "    Output(component_id=\"chart-left\", component_property=\"figure\",\n",
    "           allow_duplicate=True),\n",
    "    Output(component_id=\"chart-right\", component_property=\"figure\",\n",
    "           allow_duplicate=True),\n",
    "    Input(component_id=\"chart-left\", component_property=\"restyleData\"),\n",
    "    State('chart-left', 'figure'),\n",
    "    State('chart-right', 'figure'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def _list_update_legends(list_legend_points, dict_left, dict_right):\n",
    "    # ====================================================\n",
    "    # TODO: Combine the two callbacks by using the following context property\n",
    "    # TODO: list(ctx.triggered_prop_ids.keys())[0].split('.')[1]\n",
    "    # TODO: This will either return restyleData or relayoutData\n",
    "    # ====================================================\n",
    "    chart_left_updated = Patch()\n",
    "    chart_right_updated = Patch()\n",
    "    if list_legend_points:\n",
    "        # Legend click gives the following output\n",
    "        # [{\"visible\": [\"legendonly\"]}, [10]]\n",
    "        # [{\"visible\": [true]}, [1]]\n",
    "\n",
    "        for int_i, int_legend_point in enumerate(list_legend_points[1]):\n",
    "            for int_j, dict_one_trace in enumerate(dict_right['data']):\n",
    "                if dict_one_trace['name'].startswith(\n",
    "                        str(int_legend_point) + '.'):\n",
    "                    if isinstance(\n",
    "                        list_legend_points[0]['visible'][int_i], bool) and (\n",
    "                        list_legend_points[0]['visible'][int_i], bool == True):\n",
    "                        chart_right_updated['data'][int_j][\n",
    "                            'visible'] = True\n",
    "                    else:\n",
    "                        chart_right_updated['data'][int_j][\n",
    "                            'visible'] = False\n",
    "    else:\n",
    "        raise PreventUpdate\n",
    "\n",
    "    return chart_left_updated, chart_right_updated\n",
    "'''\n",
    "\n",
    "@callback(\n",
    "    Output(component_id=\"chart-left\", component_property=\"figure\"),\n",
    "    Output(component_id=\"chart-right\", component_property=\"figure\"),\n",
    "    Input(component_id=\"chart-left\", component_property=\"relayoutData\"),\n",
    "    State('chart-left', 'figure'),\n",
    "    State('chart-right', 'figure'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def _list_update_zooms(dict_selected_range, dict_left, dict_right):\n",
    "\n",
    "    # ==============================================\n",
    "    # TODO: Update radial and angular axis of the right chart with the gray\n",
    "    # TODO: color to indicate the success of zooming\n",
    "    # ==============================================\n",
    "\n",
    "    chart_left_updated = Patch()\n",
    "    chart_right_updated = Patch()\n",
    "\n",
    "    if dict_selected_range and (\n",
    "            'polar.radialaxis.range' in dict_selected_range):\n",
    "\n",
    "        dict_radial_range = dict_selected_range['polar.radialaxis.range']\n",
    "\n",
    "        for int_i, trace in enumerate(dict_left['data']):\n",
    "            if 'name' in trace and trace['name'] == 'Selection':\n",
    "                del chart_left_updated['data'][int_i]\n",
    "\n",
    "        # Here we check if double click was not detected. If it was detected\n",
    "        # we just had to remove the Selection trace, which we did above.\n",
    "        # If it was not detected, that means we have to create a new Selection\n",
    "        # {  'polar.angularaxis.rotation': 0,\n",
    "        #    'polar.radialaxis.angle': 0,\n",
    "        #    'polar.radialaxis.range': [0, 16.353330541878254]\n",
    "        # }\n",
    "        if 'polar.angularaxis.rotation' not in dict_selected_range and (\n",
    "                'polar.radialaxis.angle' not in dict_selected_range):\n",
    "\n",
    "            # We create a circular rectangle of 60 points by creating them and\n",
    "            # connecting them with a line\n",
    "            np_alpha = np.linspace(0, _INT_MAX_THETA, 60).tolist()\n",
    "            np_selection_theta = np_alpha + np_alpha[::-1] + [np_alpha[0]]\n",
    "\n",
    "            chart_left_updated['data'].append(\n",
    "                go.Scatterpolar(r=[dict_radial_range[0]]*60 +\\\n",
    "                                  [dict_radial_range[1]]*60 +\\\n",
    "                                  [dict_radial_range[0]],\n",
    "                                theta =np_selection_theta,\n",
    "                                name='Selection',\n",
    "                                fill='toself',\n",
    "                                mode='lines',\n",
    "                                showlegend=False,\n",
    "                                line=dict(\n",
    "                                    color='lightgrey',\n",
    "                                    dash='dot',\n",
    "                                    width=2)))\n",
    "\n",
    "        chart_left_updated['layout']['polar'][\"radialaxis\"][\n",
    "            \"autorange\"] = False\n",
    "        chart_left_updated['layout']['polar'][\"radialaxis\"][\n",
    "            'rangemode'] = 'normal'\n",
    "        chart_right_updated['layout']['polar'][\"radialaxis\"][\n",
    "            \"autorange\"] = False\n",
    "        chart_right_updated['layout']['polar'][\"radialaxis\"][\n",
    "            'rangemode'] = 'normal'\n",
    "\n",
    "        chart_left_updated['layout']['polar'][\"radialaxis\"][\n",
    "            \"range\"] = [0, _FLOAT_MAX_R]\n",
    "        chart_right_updated['layout']['polar'][\"radialaxis\"][\n",
    "            \"range\"] = [dict_radial_range[0], dict_radial_range[1]]\n",
    "\n",
    "    else:\n",
    "        raise PreventUpdate\n",
    "\n",
    "    return chart_left_updated, chart_right_updated\n",
    "\n",
    "\n",
    "app_create_dashboard(df_wine_data, 'alcohol', 'mid', 'scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c89502-cd13-478a-ba81-cfe102adae1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
